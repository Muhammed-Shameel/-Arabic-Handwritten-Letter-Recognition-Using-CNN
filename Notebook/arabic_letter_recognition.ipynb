{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abe3c030",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import sklearn \n",
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4b4dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(r\"C:\\Users\\Acer\\Downloads\\Arabic Handwritten Characters Dataset CSV\\Dataset\\csvTrainImages 13440x1024.csv\")\n",
    "train_labels = pd.read_csv(r\"C:\\Users\\Acer\\Downloads\\Arabic Handwritten Characters Dataset CSV\\Dataset\\csvTrainLabel 13440x1.csv\")\n",
    "test_data = pd.read_csv(r\"C:\\Users\\Acer\\Downloads\\Arabic Handwritten Characters Dataset CSV\\Dataset\\csvTestImages 3360x1024.csv\")\n",
    "test_labels = pd.read_csv(r\"C:\\Users\\Acer\\Downloads\\Arabic Handwritten Characters Dataset CSV\\Dataset\\csvTestLabel 3360x1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb18fb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to NumPy arrays\n",
    "X_train = train_data.values\n",
    "y_train = train_labels.values.ravel()\n",
    "\n",
    "X_test = test_data.values\n",
    "y_test = test_labels.values.ravel()\n",
    "\n",
    "# Reshape into 32x32 grayscale images\n",
    "X_train = X_train.reshape(-1, 32, 32, 1)\n",
    "X_test = X_test.reshape(-1, 32, 32, 1)\n",
    "\n",
    "# Normalize pixel values (0–255 → 0–1)\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0253a441",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train - 1\n",
    "y_test = y_test - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d71273f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5eddff79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "Basicmodel = models.Sequential([\n",
    "                layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 1)),\n",
    "                layers.MaxPooling2D((3, 3)),\n",
    "                layers.Flatten(),\n",
    "                layers.Dense(128, activation='relu'),\n",
    "                layers.Dense(28, activation='softmax')\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1f8a601",
   "metadata": {},
   "outputs": [],
   "source": [
    "Basicmodel.compile(optimizer='adam',\n",
    "                   loss='sparse_categorical_crossentropy',\n",
    "                     metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54a93361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.4570 - loss: 1.8082 - val_accuracy: 0.6454 - val_loss: 1.1080\n",
      "Epoch 2/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.7240 - loss: 0.8484 - val_accuracy: 0.7592 - val_loss: 0.7247\n",
      "Epoch 3/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.8087 - loss: 0.5705 - val_accuracy: 0.7913 - val_loss: 0.6310\n",
      "Epoch 4/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.8628 - loss: 0.4206 - val_accuracy: 0.8190 - val_loss: 0.5322\n",
      "Epoch 5/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.8914 - loss: 0.3264 - val_accuracy: 0.8273 - val_loss: 0.5053\n",
      "Epoch 6/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9155 - loss: 0.2596 - val_accuracy: 0.8473 - val_loss: 0.4702\n",
      "Epoch 7/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9286 - loss: 0.2195 - val_accuracy: 0.8354 - val_loss: 0.5245\n",
      "Epoch 8/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9464 - loss: 0.1697 - val_accuracy: 0.8580 - val_loss: 0.4786\n",
      "Epoch 9/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9553 - loss: 0.1426 - val_accuracy: 0.8711 - val_loss: 0.4450\n",
      "Epoch 10/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9648 - loss: 0.1153 - val_accuracy: 0.8413 - val_loss: 0.5024\n",
      "Epoch 11/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9661 - loss: 0.1033 - val_accuracy: 0.8657 - val_loss: 0.4572\n",
      "Epoch 12/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9749 - loss: 0.0819 - val_accuracy: 0.8741 - val_loss: 0.4407\n",
      "Epoch 13/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9779 - loss: 0.0728 - val_accuracy: 0.8705 - val_loss: 0.4962\n",
      "Epoch 14/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9812 - loss: 0.0613 - val_accuracy: 0.8675 - val_loss: 0.5003\n",
      "Epoch 15/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9830 - loss: 0.0574 - val_accuracy: 0.8628 - val_loss: 0.5322\n",
      "Epoch 16/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9871 - loss: 0.0480 - val_accuracy: 0.8663 - val_loss: 0.5160\n",
      "Epoch 17/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9868 - loss: 0.0443 - val_accuracy: 0.8708 - val_loss: 0.5293\n",
      "Epoch 18/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9879 - loss: 0.0436 - val_accuracy: 0.8586 - val_loss: 0.5587\n",
      "Epoch 19/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9882 - loss: 0.0402 - val_accuracy: 0.8765 - val_loss: 0.5103\n",
      "Epoch 20/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9930 - loss: 0.0277 - val_accuracy: 0.8696 - val_loss: 0.5534\n",
      "Epoch 21/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9940 - loss: 0.0237 - val_accuracy: 0.8765 - val_loss: 0.5363\n",
      "Epoch 22/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9958 - loss: 0.0195 - val_accuracy: 0.8684 - val_loss: 0.5804\n",
      "Epoch 23/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9881 - loss: 0.0383 - val_accuracy: 0.8589 - val_loss: 0.6353\n",
      "Epoch 24/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9929 - loss: 0.0265 - val_accuracy: 0.8821 - val_loss: 0.5214\n",
      "Epoch 25/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9987 - loss: 0.0096 - val_accuracy: 0.8860 - val_loss: 0.5397\n"
     ]
    }
   ],
   "source": [
    "history = Basicmodel.fit(X_train, y_train, epochs=25, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53a1c61c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96       119\n",
      "           1       0.90      0.95      0.92       120\n",
      "           2       0.77      0.77      0.77       120\n",
      "           3       0.82      0.80      0.81       120\n",
      "           4       0.90      0.87      0.88       120\n",
      "           5       0.79      0.88      0.83       120\n",
      "           6       0.84      0.89      0.87       120\n",
      "           7       0.90      0.85      0.88       120\n",
      "           8       0.84      0.85      0.85       120\n",
      "           9       0.85      0.96      0.90       120\n",
      "          10       0.94      0.84      0.89       120\n",
      "          11       0.85      0.91      0.88       120\n",
      "          12       0.95      0.95      0.95       120\n",
      "          13       0.88      0.88      0.88       120\n",
      "          14       0.94      0.84      0.89       120\n",
      "          15       0.90      0.92      0.91       120\n",
      "          16       0.92      0.88      0.90       120\n",
      "          17       0.90      0.83      0.87       120\n",
      "          18       0.94      0.85      0.89       120\n",
      "          19       0.80      0.88      0.83       120\n",
      "          20       0.81      0.80      0.81       120\n",
      "          21       0.93      0.90      0.92       120\n",
      "          22       0.92      0.97      0.94       120\n",
      "          23       0.96      0.96      0.96       120\n",
      "          24       0.87      0.85      0.86       120\n",
      "          25       0.92      0.92      0.92       120\n",
      "          26       0.90      0.93      0.92       120\n",
      "          27       0.97      0.90      0.94       120\n",
      "\n",
      "    accuracy                           0.89      3359\n",
      "   macro avg       0.89      0.89      0.89      3359\n",
      "weighted avg       0.89      0.89      0.89      3359\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = Basicmodel.predict(X_test)\n",
    "y_pred_classes = y_pred.argmax(axis=1)\n",
    "\n",
    "print(classification_report(y_test, y_pred_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "716ff057",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "Firstmodel = models.Sequential([\n",
    "                layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 1)),\n",
    "                layers.MaxPooling2D((2, 2)),\n",
    "                layers.Dropout(0.25),\n",
    "                layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "                layers.MaxPooling2D((2, 2)),\n",
    "                layers.Dropout(0.25),\n",
    "                layers.Flatten(),\n",
    "                layers.Dense(256, activation='relu'),\n",
    "                layers.Dropout(0.3),\n",
    "                layers.Dense(28, activation='softmax')\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9df71ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.4364 - loss: 1.8217 - val_accuracy: 0.7526 - val_loss: 0.8055\n",
      "Epoch 2/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.7341 - loss: 0.8082 - val_accuracy: 0.8565 - val_loss: 0.4929\n",
      "Epoch 3/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - accuracy: 0.8152 - loss: 0.5503 - val_accuracy: 0.8884 - val_loss: 0.3672\n",
      "Epoch 4/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - accuracy: 0.8507 - loss: 0.4399 - val_accuracy: 0.9080 - val_loss: 0.3071\n",
      "Epoch 5/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.8808 - loss: 0.3529 - val_accuracy: 0.9029 - val_loss: 0.3168\n",
      "Epoch 6/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.8975 - loss: 0.3054 - val_accuracy: 0.9190 - val_loss: 0.2655\n",
      "Epoch 7/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.9103 - loss: 0.2628 - val_accuracy: 0.9271 - val_loss: 0.2578\n",
      "Epoch 8/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.9191 - loss: 0.2358 - val_accuracy: 0.9283 - val_loss: 0.2452\n",
      "Epoch 9/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.9284 - loss: 0.2088 - val_accuracy: 0.9303 - val_loss: 0.2291\n",
      "Epoch 10/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.9336 - loss: 0.1858 - val_accuracy: 0.9405 - val_loss: 0.2130\n",
      "Epoch 11/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.9401 - loss: 0.1692 - val_accuracy: 0.9381 - val_loss: 0.2195\n",
      "Epoch 12/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.9455 - loss: 0.1588 - val_accuracy: 0.9428 - val_loss: 0.2073\n",
      "Epoch 13/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.9466 - loss: 0.1523 - val_accuracy: 0.9384 - val_loss: 0.2229\n",
      "Epoch 14/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.9527 - loss: 0.1363 - val_accuracy: 0.9393 - val_loss: 0.2158\n",
      "Epoch 15/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.9547 - loss: 0.1306 - val_accuracy: 0.9416 - val_loss: 0.2067\n",
      "Epoch 16/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.9568 - loss: 0.1237 - val_accuracy: 0.9464 - val_loss: 0.2037\n",
      "Epoch 17/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.9591 - loss: 0.1150 - val_accuracy: 0.9443 - val_loss: 0.2138\n",
      "Epoch 18/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.9621 - loss: 0.1079 - val_accuracy: 0.9419 - val_loss: 0.2184\n",
      "Epoch 19/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.9629 - loss: 0.1073 - val_accuracy: 0.9411 - val_loss: 0.2350\n",
      "Epoch 20/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.9630 - loss: 0.1051 - val_accuracy: 0.9414 - val_loss: 0.2297\n",
      "Epoch 21/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.9676 - loss: 0.0983 - val_accuracy: 0.9458 - val_loss: 0.2216\n",
      "Epoch 22/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.9732 - loss: 0.0765 - val_accuracy: 0.9512 - val_loss: 0.2265\n",
      "Epoch 23/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.9697 - loss: 0.0862 - val_accuracy: 0.9431 - val_loss: 0.2397\n",
      "Epoch 24/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.9698 - loss: 0.0891 - val_accuracy: 0.9506 - val_loss: 0.2173\n",
      "Epoch 25/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.9745 - loss: 0.0777 - val_accuracy: 0.9461 - val_loss: 0.2351\n"
     ]
    }
   ],
   "source": [
    "Firstmodel.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = Firstmodel.fit(X_train, y_train, epochs=25, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54da738e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       119\n",
      "           1       0.97      0.98      0.98       120\n",
      "           2       0.83      0.95      0.89       120\n",
      "           3       0.95      0.80      0.87       120\n",
      "           4       0.96      0.93      0.94       120\n",
      "           5       0.90      0.94      0.92       120\n",
      "           6       0.96      0.93      0.95       120\n",
      "           7       0.91      0.95      0.93       120\n",
      "           8       0.96      0.89      0.92       120\n",
      "           9       0.89      0.99      0.94       120\n",
      "          10       0.94      0.92      0.93       120\n",
      "          11       0.99      0.97      0.98       120\n",
      "          12       0.94      0.98      0.96       120\n",
      "          13       0.93      0.97      0.95       120\n",
      "          14       0.96      0.92      0.94       120\n",
      "          15       0.93      0.97      0.95       120\n",
      "          16       0.95      0.93      0.94       120\n",
      "          17       0.96      0.97      0.96       120\n",
      "          18       0.96      0.94      0.95       120\n",
      "          19       0.93      0.94      0.94       120\n",
      "          20       0.94      0.92      0.93       120\n",
      "          21       0.99      0.95      0.97       120\n",
      "          22       0.97      1.00      0.98       120\n",
      "          23       0.99      0.99      0.99       120\n",
      "          24       0.94      0.89      0.91       120\n",
      "          25       0.94      0.96      0.95       120\n",
      "          26       0.96      0.94      0.95       120\n",
      "          27       0.98      0.97      0.98       120\n",
      "\n",
      "    accuracy                           0.95      3359\n",
      "   macro avg       0.95      0.95      0.95      3359\n",
      "weighted avg       0.95      0.95      0.95      3359\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = Firstmodel.predict(X_test)\n",
    "y_pred_classes = y_pred.argmax(axis=1)\n",
    "\n",
    "print(classification_report(y_test, y_pred_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35761e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "FinalmodelV1 = models.Sequential([\n",
    "                layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 1)),\n",
    "                layers.MaxPooling2D((2, 2)),\n",
    "                layers.Dropout(0.25),\n",
    "                layers.BatchNormalization(),\n",
    "                layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "                layers.MaxPooling2D((2, 2)),\n",
    "                layers.Dropout(0.25),\n",
    "                layers.BatchNormalization(),\n",
    "                layers.Flatten(),\n",
    "                layers.Dense(256, activation='relu'),\n",
    "                layers.Dropout(0.3),\n",
    "                layers.BatchNormalization(),\n",
    "                layers.Dense(28, activation='softmax')\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd915e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 23ms/step - accuracy: 0.4793 - loss: 1.7368 - val_accuracy: 0.0646 - val_loss: 6.7179\n",
      "Epoch 2/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.7617 - loss: 0.7558 - val_accuracy: 0.7767 - val_loss: 0.7301\n",
      "Epoch 3/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.8327 - loss: 0.5303 - val_accuracy: 0.8622 - val_loss: 0.4585\n",
      "Epoch 4/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.8699 - loss: 0.4180 - val_accuracy: 0.8994 - val_loss: 0.3426\n",
      "Epoch 5/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - accuracy: 0.8859 - loss: 0.3470 - val_accuracy: 0.9202 - val_loss: 0.2663\n",
      "Epoch 6/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.9051 - loss: 0.2964 - val_accuracy: 0.9247 - val_loss: 0.2531\n",
      "Epoch 7/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.9113 - loss: 0.2692 - val_accuracy: 0.9172 - val_loss: 0.2503\n",
      "Epoch 8/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.9190 - loss: 0.2484 - val_accuracy: 0.9330 - val_loss: 0.2236\n",
      "Epoch 9/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.9259 - loss: 0.2219 - val_accuracy: 0.9223 - val_loss: 0.2562\n",
      "Epoch 10/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.9312 - loss: 0.2034 - val_accuracy: 0.9470 - val_loss: 0.1775\n",
      "Epoch 11/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.9381 - loss: 0.1841 - val_accuracy: 0.9530 - val_loss: 0.1659\n",
      "Epoch 12/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.9430 - loss: 0.1777 - val_accuracy: 0.9280 - val_loss: 0.2321\n",
      "Epoch 13/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.9437 - loss: 0.1626 - val_accuracy: 0.9479 - val_loss: 0.1881\n",
      "Epoch 14/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.9451 - loss: 0.1548 - val_accuracy: 0.9408 - val_loss: 0.2220\n",
      "Epoch 15/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.9510 - loss: 0.1480 - val_accuracy: 0.9506 - val_loss: 0.1593\n",
      "Epoch 16/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.9522 - loss: 0.1423 - val_accuracy: 0.9357 - val_loss: 0.2311\n",
      "Epoch 17/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.9561 - loss: 0.1310 - val_accuracy: 0.9518 - val_loss: 0.1726\n",
      "Epoch 18/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.9548 - loss: 0.1282 - val_accuracy: 0.9503 - val_loss: 0.1761\n",
      "Epoch 19/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.9594 - loss: 0.1182 - val_accuracy: 0.9503 - val_loss: 0.1723\n",
      "Epoch 20/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - accuracy: 0.9600 - loss: 0.1191 - val_accuracy: 0.9527 - val_loss: 0.1768\n",
      "Epoch 21/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 19ms/step - accuracy: 0.9597 - loss: 0.1186 - val_accuracy: 0.9488 - val_loss: 0.1845\n",
      "Epoch 22/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.9626 - loss: 0.1103 - val_accuracy: 0.9583 - val_loss: 0.1646\n",
      "Epoch 23/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.9665 - loss: 0.1002 - val_accuracy: 0.9503 - val_loss: 0.1870\n",
      "Epoch 24/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 74ms/step - accuracy: 0.9641 - loss: 0.1013 - val_accuracy: 0.9589 - val_loss: 0.1605\n",
      "Epoch 25/25\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.9609 - loss: 0.1099 - val_accuracy: 0.9419 - val_loss: 0.2250\n"
     ]
    }
   ],
   "source": [
    "FinalmodelV1.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = FinalmodelV1.fit(X_train, y_train, epochs=25, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22f464f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       119\n",
      "           1       0.97      0.98      0.98       120\n",
      "           2       0.83      0.95      0.89       120\n",
      "           3       0.95      0.80      0.87       120\n",
      "           4       0.96      0.93      0.94       120\n",
      "           5       0.90      0.94      0.92       120\n",
      "           6       0.96      0.93      0.95       120\n",
      "           7       0.91      0.95      0.93       120\n",
      "           8       0.96      0.89      0.92       120\n",
      "           9       0.89      0.99      0.94       120\n",
      "          10       0.94      0.92      0.93       120\n",
      "          11       0.99      0.97      0.98       120\n",
      "          12       0.94      0.98      0.96       120\n",
      "          13       0.93      0.97      0.95       120\n",
      "          14       0.96      0.92      0.94       120\n",
      "          15       0.93      0.97      0.95       120\n",
      "          16       0.95      0.93      0.94       120\n",
      "          17       0.96      0.97      0.96       120\n",
      "          18       0.96      0.94      0.95       120\n",
      "          19       0.93      0.94      0.94       120\n",
      "          20       0.94      0.92      0.93       120\n",
      "          21       0.99      0.95      0.97       120\n",
      "          22       0.97      1.00      0.98       120\n",
      "          23       0.99      0.99      0.99       120\n",
      "          24       0.94      0.89      0.91       120\n",
      "          25       0.94      0.96      0.95       120\n",
      "          26       0.96      0.94      0.95       120\n",
      "          27       0.98      0.97      0.98       120\n",
      "\n",
      "    accuracy                           0.95      3359\n",
      "   macro avg       0.95      0.95      0.95      3359\n",
      "weighted avg       0.95      0.95      0.95      3359\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = Firstmodel.predict(X_test)\n",
    "y_pred_classes = y_pred.argmax(axis=1)\n",
    "\n",
    "print(classification_report(y_test, y_pred_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c249d912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - accuracy: 0.2358 - loss: 2.6196 - val_accuracy: 0.0360 - val_loss: 5.7630\n",
      "Epoch 2/30\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - accuracy: 0.5007 - loss: 1.5114 - val_accuracy: 0.2158 - val_loss: 2.4616\n",
      "Epoch 3/30\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 34ms/step - accuracy: 0.6402 - loss: 1.0654 - val_accuracy: 0.6773 - val_loss: 0.8471\n",
      "Epoch 4/30\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - accuracy: 0.7121 - loss: 0.8508 - val_accuracy: 0.8449 - val_loss: 0.4369\n",
      "Epoch 5/30\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - accuracy: 0.7587 - loss: 0.7272 - val_accuracy: 0.8866 - val_loss: 0.3494\n",
      "Epoch 6/30\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 34ms/step - accuracy: 0.7949 - loss: 0.6178 - val_accuracy: 0.6002 - val_loss: 1.2309\n",
      "Epoch 7/30\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 35ms/step - accuracy: 0.8126 - loss: 0.5628 - val_accuracy: 0.8973 - val_loss: 0.2821\n",
      "Epoch 8/30\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - accuracy: 0.8263 - loss: 0.5196 - val_accuracy: 0.6812 - val_loss: 0.9822\n",
      "Epoch 9/30\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 34ms/step - accuracy: 0.8359 - loss: 0.4927 - val_accuracy: 0.9050 - val_loss: 0.2772\n",
      "Epoch 10/30\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - accuracy: 0.8477 - loss: 0.4534 - val_accuracy: 0.8366 - val_loss: 0.4466\n",
      "Epoch 11/30\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 34ms/step - accuracy: 0.8516 - loss: 0.4377 - val_accuracy: 0.9363 - val_loss: 0.1919\n",
      "Epoch 12/30\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - accuracy: 0.8668 - loss: 0.4015 - val_accuracy: 0.9342 - val_loss: 0.1969\n",
      "Epoch 13/30\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 34ms/step - accuracy: 0.8731 - loss: 0.3880 - val_accuracy: 0.9422 - val_loss: 0.1735\n",
      "Epoch 14/30\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - accuracy: 0.8764 - loss: 0.3719 - val_accuracy: 0.9539 - val_loss: 0.1492\n",
      "Epoch 15/30\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 34ms/step - accuracy: 0.8781 - loss: 0.3688 - val_accuracy: 0.9547 - val_loss: 0.1395\n",
      "Epoch 16/30\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 34ms/step - accuracy: 0.8835 - loss: 0.3516 - val_accuracy: 0.8211 - val_loss: 0.4616\n",
      "Epoch 17/30\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - accuracy: 0.8864 - loss: 0.3349 - val_accuracy: 0.9533 - val_loss: 0.1501\n",
      "Epoch 18/30\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 34ms/step - accuracy: 0.8840 - loss: 0.3412 - val_accuracy: 0.9509 - val_loss: 0.1481\n",
      "Epoch 19/30\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 34ms/step - accuracy: 0.8929 - loss: 0.3285 - val_accuracy: 0.9053 - val_loss: 0.2639\n",
      "Epoch 20/30\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - accuracy: 0.8959 - loss: 0.3155 - val_accuracy: 0.9580 - val_loss: 0.1310\n",
      "Epoch 21/30\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 34ms/step - accuracy: 0.9018 - loss: 0.2933 - val_accuracy: 0.9678 - val_loss: 0.1083\n",
      "Epoch 22/30\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 34ms/step - accuracy: 0.8996 - loss: 0.3055 - val_accuracy: 0.9440 - val_loss: 0.1698\n",
      "Epoch 23/30\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 34ms/step - accuracy: 0.9080 - loss: 0.2809 - val_accuracy: 0.8726 - val_loss: 0.3447\n",
      "Epoch 24/30\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - accuracy: 0.9064 - loss: 0.2847 - val_accuracy: 0.9655 - val_loss: 0.1127\n",
      "Epoch 25/30\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 41ms/step - accuracy: 0.9077 - loss: 0.2838 - val_accuracy: 0.9149 - val_loss: 0.2245\n",
      "Epoch 26/30\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - accuracy: 0.9097 - loss: 0.2761 - val_accuracy: 0.9678 - val_loss: 0.1003\n",
      "Epoch 27/30\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - accuracy: 0.9114 - loss: 0.2695 - val_accuracy: 0.9402 - val_loss: 0.1731\n",
      "Epoch 28/30\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - accuracy: 0.9134 - loss: 0.2623 - val_accuracy: 0.9646 - val_loss: 0.1147\n",
      "Epoch 29/30\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - accuracy: 0.9134 - loss: 0.2653 - val_accuracy: 0.9038 - val_loss: 0.2522\n",
      "Epoch 30/30\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - accuracy: 0.9159 - loss: 0.2524 - val_accuracy: 0.9661 - val_loss: 0.1148\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_17\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_17\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_80 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_69          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ p_re_lu_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PReLU</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,816</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_81 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_70          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ p_re_lu_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PReLU</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_82 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_71          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_52 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ p_re_lu_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PReLU</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_72          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_83 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_53 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_73          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_84 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_54 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,612</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_48 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_47 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_80 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_69          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_49 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ p_re_lu_10 (\u001b[38;5;33mPReLU\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m10,816\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_48 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_81 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_70          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_50 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ p_re_lu_11 (\u001b[38;5;33mPReLU\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_49 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_82 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_71          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_17 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_52 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ p_re_lu_12 (\u001b[38;5;33mPReLU\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_72          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_83 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_53 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_4 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_73          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_84 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_54 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m)             │         \u001b[38;5;34m3,612\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">825,750</span> (3.15 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m825,750\u001b[0m (3.15 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">274,844</span> (1.05 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m274,844\u001b[0m (1.05 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,216</span> (4.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,216\u001b[0m (4.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">549,690</span> (2.10 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m549,690\u001b[0m (2.10 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.activations import swish\n",
    "from tensorflow.keras.metrics import Precision, Recall, CategoricalAccuracy\n",
    "from tensorflow.keras.layers import BatchNormalization, PReLU\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1\n",
    ")\n",
    "\n",
    "datagen.fit(X_train)\n",
    "\n",
    "Lastmodel = models.Sequential([\n",
    "                layers.Conv2D(32, (3, 3), activation='elu', input_shape=(32, 32, 1)),\n",
    "                layers.MaxPooling2D((2, 2)),\n",
    "                layers.Dropout(0.25),\n",
    "                layers.BatchNormalization(),\n",
    "                layers.Conv2D(64, (3, 3)),\n",
    "                layers.PReLU(),\n",
    "                layers.MaxPooling2D((2, 2)),\n",
    "                layers.Dropout(0.25),\n",
    "                layers.BatchNormalization(),\n",
    "                layers.Conv2D(128, (3, 3)),\n",
    "                layers.PReLU(),\n",
    "                layers.MaxPooling2D((2, 2)),\n",
    "                layers.Dropout(0.25),\n",
    "                layers.BatchNormalization(),\n",
    "                layers.Flatten(),\n",
    "                layers.Dense(256),\n",
    "                layers.PReLU(),\n",
    "                layers.BatchNormalization(),\n",
    "                layers.Dropout(0.2),\n",
    "                layers.Dense(128),\n",
    "                layers.LeakyReLU(),\n",
    "                layers.BatchNormalization(),\n",
    "                layers.Dropout(0.2),\n",
    "                layers.Dense(28, activation='softmax')\n",
    "            ])\n",
    "\n",
    "Lastmodel.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "history = Lastmodel.fit(datagen.flow(X_train, y_train, batch_size=64),\n",
    "                        epochs=30, validation_data=(X_test, y_test),\n",
    "                        callbacks=[es])\n",
    "\n",
    "Lastmodel.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e96428e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       119\n",
      "           1       0.98      0.99      0.99       120\n",
      "           2       0.89      0.99      0.94       120\n",
      "           3       0.99      0.93      0.96       120\n",
      "           4       0.95      0.99      0.97       120\n",
      "           5       0.97      0.94      0.96       120\n",
      "           6       0.95      0.98      0.97       120\n",
      "           7       0.96      0.97      0.97       120\n",
      "           8       0.94      0.95      0.95       120\n",
      "           9       0.94      0.97      0.96       120\n",
      "          10       0.98      0.92      0.95       120\n",
      "          11       0.99      1.00      1.00       120\n",
      "          12       0.98      1.00      0.99       120\n",
      "          13       0.95      0.99      0.97       120\n",
      "          14       0.99      0.96      0.97       120\n",
      "          15       0.97      0.94      0.95       120\n",
      "          16       0.95      0.97      0.96       120\n",
      "          17       0.98      0.97      0.97       120\n",
      "          18       0.99      0.97      0.98       120\n",
      "          19       0.98      0.90      0.94       120\n",
      "          20       0.89      0.97      0.93       120\n",
      "          21       0.98      0.98      0.98       120\n",
      "          22       0.99      0.99      0.99       120\n",
      "          23       0.99      0.97      0.98       120\n",
      "          24       0.98      0.92      0.95       120\n",
      "          25       0.97      0.97      0.97       120\n",
      "          26       0.97      0.97      0.97       120\n",
      "          27       0.99      0.98      0.99       120\n",
      "\n",
      "    accuracy                           0.97      3359\n",
      "   macro avg       0.97      0.97      0.97      3359\n",
      "weighted avg       0.97      0.97      0.97      3359\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = Lastmodel.predict(X_test)\n",
    "y_pred_classes = y_pred.argmax(axis=1)\n",
    "\n",
    "print(classification_report(y_test, y_pred_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "058a7184",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 60ms/step - accuracy: 0.1760 - loss: 2.8289 - val_accuracy: 0.0357 - val_loss: 4.8287\n",
      "Epoch 2/30\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 137ms/step - accuracy: 0.3644 - loss: 1.8960 - val_accuracy: 0.1075 - val_loss: 3.5195\n",
      "Epoch 3/30\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 77ms/step - accuracy: 0.5462 - loss: 1.3704 - val_accuracy: 0.6529 - val_loss: 1.0208\n",
      "Epoch 4/30\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 171ms/step - accuracy: 0.6572 - loss: 1.0422 - val_accuracy: 0.8687 - val_loss: 0.4094\n",
      "Epoch 5/30\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 72ms/step - accuracy: 0.7276 - loss: 0.8319 - val_accuracy: 0.8976 - val_loss: 0.3026\n",
      "Epoch 6/30\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 204ms/step - accuracy: 0.7693 - loss: 0.7052 - val_accuracy: 0.9029 - val_loss: 0.2703\n",
      "Epoch 7/30\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 202ms/step - accuracy: 0.8007 - loss: 0.6252 - val_accuracy: 0.9238 - val_loss: 0.2260\n",
      "Epoch 8/30\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 110ms/step - accuracy: 0.8135 - loss: 0.5811 - val_accuracy: 0.9256 - val_loss: 0.1992\n",
      "Epoch 9/30\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 69ms/step - accuracy: 0.8380 - loss: 0.5204 - val_accuracy: 0.9411 - val_loss: 0.1849\n",
      "Epoch 10/30\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 60ms/step - accuracy: 0.8393 - loss: 0.5106 - val_accuracy: 0.9405 - val_loss: 0.1746\n",
      "Epoch 11/30\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 60ms/step - accuracy: 0.8521 - loss: 0.4693 - val_accuracy: 0.9506 - val_loss: 0.1568\n",
      "Epoch 12/30\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 59ms/step - accuracy: 0.8660 - loss: 0.4295 - val_accuracy: 0.9559 - val_loss: 0.1401\n",
      "Epoch 13/30\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 58ms/step - accuracy: 0.8681 - loss: 0.4266 - val_accuracy: 0.9574 - val_loss: 0.1448\n",
      "Epoch 14/30\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 57ms/step - accuracy: 0.8766 - loss: 0.4045 - val_accuracy: 0.9616 - val_loss: 0.1362\n",
      "Epoch 15/30\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 57ms/step - accuracy: 0.8755 - loss: 0.4010 - val_accuracy: 0.9515 - val_loss: 0.1516\n",
      "Epoch 16/30\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 57ms/step - accuracy: 0.8848 - loss: 0.3670 - val_accuracy: 0.9607 - val_loss: 0.1279\n",
      "Epoch 17/30\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 59ms/step - accuracy: 0.8877 - loss: 0.3694 - val_accuracy: 0.9696 - val_loss: 0.1127\n",
      "Epoch 18/30\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 57ms/step - accuracy: 0.8937 - loss: 0.3432 - val_accuracy: 0.9690 - val_loss: 0.1118\n",
      "Epoch 19/30\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 59ms/step - accuracy: 0.8934 - loss: 0.3455 - val_accuracy: 0.9690 - val_loss: 0.1134\n",
      "Epoch 20/30\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 61ms/step - accuracy: 0.8964 - loss: 0.3331 - val_accuracy: 0.9628 - val_loss: 0.1196\n",
      "Epoch 21/30\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 71ms/step - accuracy: 0.9007 - loss: 0.3237 - val_accuracy: 0.9681 - val_loss: 0.1145\n",
      "Epoch 22/30\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 161ms/step - accuracy: 0.9057 - loss: 0.3146 - val_accuracy: 0.9681 - val_loss: 0.1127\n",
      "Epoch 23/30\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 117ms/step - accuracy: 0.9016 - loss: 0.3171 - val_accuracy: 0.9738 - val_loss: 0.0981\n",
      "Epoch 24/30\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 61ms/step - accuracy: 0.9115 - loss: 0.2920 - val_accuracy: 0.9747 - val_loss: 0.0904\n",
      "Epoch 25/30\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 59ms/step - accuracy: 0.9091 - loss: 0.3009 - val_accuracy: 0.9750 - val_loss: 0.0924\n",
      "Epoch 26/30\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - accuracy: 0.9149 - loss: 0.2821 - val_accuracy: 0.9747 - val_loss: 0.0918\n",
      "Epoch 27/30\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 58ms/step - accuracy: 0.9119 - loss: 0.2933 - val_accuracy: 0.9711 - val_loss: 0.1011\n",
      "Epoch 28/30\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 61ms/step - accuracy: 0.9118 - loss: 0.2834 - val_accuracy: 0.9693 - val_loss: 0.0996\n",
      "Epoch 29/30\n",
      "\u001b[1m210/210\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 170ms/step - accuracy: 0.9146 - loss: 0.2781 - val_accuracy: 0.9741 - val_loss: 0.0988\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_22\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_22\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_65 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ p_re_lu_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PReLU</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">28,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_62 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_107 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_96          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_66 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ p_re_lu_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PReLU</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,816</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_63 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_108 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_97          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_67 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ p_re_lu_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PReLU</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_64 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_109 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_98          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_68 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ p_re_lu_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PReLU</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_65 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_110 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_99          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_69 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ p_re_lu_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PReLU</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_100         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_111 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_70 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_101         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_112 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_71 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,612</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_102         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_113 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_72 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">812</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_65 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ p_re_lu_27 (\u001b[38;5;33mPReLU\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │        \u001b[38;5;34m28,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_62 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_107 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_96          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_66 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ p_re_lu_28 (\u001b[38;5;33mPReLU\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m10,816\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_63 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_108 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_97          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_67 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ p_re_lu_29 (\u001b[38;5;33mPReLU\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_64 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_109 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_98          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_68 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │       \u001b[38;5;34m295,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ p_re_lu_30 (\u001b[38;5;33mPReLU\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_65 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_110 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_99          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_22 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_69 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m131,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ p_re_lu_31 (\u001b[38;5;33mPReLU\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_100         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_111 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_70 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m65,664\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_11 (\u001b[38;5;33mLeakyReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_101         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_112 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_71 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m)             │         \u001b[38;5;34m3,612\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_12 (\u001b[38;5;33mLeakyReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_102         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m)             │           \u001b[38;5;34m112\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_113 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_72 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m)             │           \u001b[38;5;34m812\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,907,322</span> (7.28 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,907,322\u001b[0m (7.28 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">635,008</span> (2.42 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m635,008\u001b[0m (2.42 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,296</span> (8.97 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,296\u001b[0m (8.97 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,270,018</span> (4.84 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m1,270,018\u001b[0m (4.84 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.activations import swish\n",
    "from tensorflow.keras.metrics import Precision, Recall, CategoricalAccuracy\n",
    "from tensorflow.keras.layers import BatchNormalization, PReLU\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1\n",
    ")\n",
    "\n",
    "datagen.fit(X_train)\n",
    "\n",
    "LastmodelV2 = models.Sequential([\n",
    "                layers.Conv2D(32, (3, 3),input_shape=(32, 32, 1)),\n",
    "                layers.PReLU(),\n",
    "                layers.MaxPooling2D((2, 2)),\n",
    "                layers.Dropout(0.25),\n",
    "                layers.BatchNormalization(),\n",
    "                layers.Conv2D(64, (3, 3)),\n",
    "                layers.PReLU(),\n",
    "                layers.MaxPooling2D((2, 2)),\n",
    "                layers.Dropout(0.25),\n",
    "                layers.BatchNormalization(),\n",
    "                layers.Conv2D(128, (3, 3)),\n",
    "                layers.PReLU(),\n",
    "                layers.MaxPooling2D((2, 2)),\n",
    "                layers.Dropout(0.25),\n",
    "                layers.BatchNormalization(),\n",
    "                layers.Conv2D(256, (3,3), padding='same'),\n",
    "                layers.PReLU(),\n",
    "                layers.MaxPooling2D((2,2)),\n",
    "                layers.Dropout(0.25),\n",
    "                layers.BatchNormalization(),\n",
    "                layers.Flatten(),\n",
    "                layers.Dense(512),\n",
    "                layers.PReLU(),\n",
    "                layers.BatchNormalization(),\n",
    "                layers.Dropout(0.2),\n",
    "                layers.Dense(128),\n",
    "                layers.LeakyReLU(),\n",
    "                layers.BatchNormalization(),\n",
    "                layers.Dropout(0.2),\n",
    "                layers.Dense(28),\n",
    "                layers.LeakyReLU(),\n",
    "                layers.BatchNormalization(),\n",
    "                layers.Dropout(0.2),\n",
    "                layers.Dense(28, activation='softmax')\n",
    "            ])\n",
    "\n",
    "LastmodelV2.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "history = LastmodelV2.fit(datagen.flow(X_train, y_train, batch_size=64),\n",
    "                        epochs=30, validation_data=(X_test, y_test),\n",
    "                        callbacks=[es])\n",
    "\n",
    "LastmodelV2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "080a88ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       119\n",
      "           1       1.00      0.98      0.99       120\n",
      "           2       0.93      0.97      0.95       120\n",
      "           3       0.97      0.98      0.98       120\n",
      "           4       0.98      0.99      0.98       120\n",
      "           5       0.97      0.97      0.97       120\n",
      "           6       1.00      0.98      0.99       120\n",
      "           7       0.94      0.98      0.96       120\n",
      "           8       0.93      0.95      0.94       120\n",
      "           9       0.95      0.96      0.95       120\n",
      "          10       0.99      0.90      0.94       120\n",
      "          11       0.99      1.00      1.00       120\n",
      "          12       0.99      0.99      0.99       120\n",
      "          13       0.98      0.98      0.98       120\n",
      "          14       0.99      0.97      0.98       120\n",
      "          15       0.97      0.99      0.98       120\n",
      "          16       0.99      0.97      0.98       120\n",
      "          17       0.97      0.97      0.97       120\n",
      "          18       0.98      0.99      0.98       120\n",
      "          19       0.97      0.95      0.96       120\n",
      "          20       0.95      0.97      0.96       120\n",
      "          21       0.98      0.99      0.99       120\n",
      "          22       0.99      0.99      0.99       120\n",
      "          23       0.99      0.97      0.98       120\n",
      "          24       0.98      0.94      0.96       120\n",
      "          25       0.98      0.97      0.97       120\n",
      "          26       0.97      0.97      0.97       120\n",
      "          27       0.98      1.00      0.99       120\n",
      "\n",
      "    accuracy                           0.97      3359\n",
      "   macro avg       0.98      0.97      0.97      3359\n",
      "weighted avg       0.98      0.97      0.97      3359\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = LastmodelV2.predict(X_test)\n",
    "y_pred_classes = y_pred.argmax(axis=1)\n",
    "\n",
    "print(classification_report(y_test, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d553d3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "LastmodelV2.save(\"LastmodelV2.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e35de462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 28 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "arabic_letters = [\n",
    "    \"ا\", \"ب\", \"ت\", \"ث\", \"ج\", \"ح\", \"خ\", \"د\", \"ذ\", \"ر\", \"ز\",\n",
    "    \"س\", \"ش\", \"ص\", \"ض\", \"ط\", \"ظ\", \"ع\", \"غ\", \"ف\", \"ق\",\n",
    "    \"ك\", \"ل\", \"م\", \"ن\", \"ه\", \"و\", \"ي\"\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "for i in range(28):\n",
    "    plt.subplot(4, 7, i + 1)\n",
    "    idx = np.where(y_train == i)[0][0]\n",
    "    \n",
    "    # Reshape to 32x32 image\n",
    "    img = X_train[idx].reshape(32, 32)\n",
    "    \n",
    "    # 🔹 Apply both transformations\n",
    "    # First rotate 90° (counterclockwise), then flip vertically\n",
    "    transformed_img = np.flipud(np.rot90(img))\n",
    "    \n",
    "    plt.imshow(transformed_img, cmap='gray')\n",
    "    plt.title(arabic_letters[i], fontsize=14)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
